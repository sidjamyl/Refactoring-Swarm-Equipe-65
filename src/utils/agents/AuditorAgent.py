from langchain_core.messages import SystemMessage, HumanMessage
from src.utils.logger import log_experiment, ActionType
from src.utils.state.stateDefinition import SwarmState
from src.utils.agents import agentTest # Assure-toi que l'import match ton projet
from src.utils.prompts.promptAuditor import AUDITOR_SYSTEM_PROMPT

def auditor_agent_node(state: SwarmState) -> dict:

    """
    Agent Auditeur : Analyse la sortie brute de Pylint et gÃ©nÃ¨re un rapport structurÃ©.
    """

   
    current_file = state["current_file"]
    raw_pylint_output = state["pylint_reports"][1]
    
    print(f"\n{'â”€'*80}")
    print(f"ğŸ•µï¸ Ã‰TAPE 2/6 : AUDIT & PLANIFICATION")
    print(f"{'â”€'*80}")
    print(f"\nğŸ“ Analyse du rapport Pylint...")
    print(f"ğŸ¤– Agent Auditeur en cours d'exÃ©cution...")
    
    system_prompt = AUDITOR_SYSTEM_PROMPT

    user_prompt = f"Target File: {current_file}\n\nRAW PYLINT OUTPUT:\n{raw_pylint_output}"

    # 3. Appel du LLM
    llm = agentTest.model
    
    try:
        response = llm.invoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ])
        audit_content = response.content
        status = "SUCCESS"
        print(f"\nâœ… Plan de refactoring gÃ©nÃ©rÃ©")
        print(f"\n{'â•”'+'â•'*78+'â•—'}")
        print(f"â•‘{' '*26}ğŸ“‹ PLAN DE REFACTORING{' '*26}â•‘")
        print(f"{'â• '+'â•'*78+'â•£'}")
        # Afficher ligne par ligne avec bordures
        for line in audit_content.split('\n')[:10]:  # Limiter Ã  10 premiÃ¨res lignes
            print(f"â•‘ {line[:76]:<76} â•‘")
        if len(audit_content.split('\n')) > 10:
            print(f"â•‘ {'... (plan complet sauvegardÃ©)':<76} â•‘")
        print(f"{'â•š'+'â•'*78+'â•'}")
        
        # input("\n[Appuyez sur EntrÃ©e pour continuer vers la lecture du code...]")
    except Exception as e:
        audit_content = f"Error generating audit: {str(e)}"
        status = "FAILURE"
        print(f"âŒ [Auditor] Erreur lors de la gÃ©nÃ©ration : {str(e)}")

    # 4. Logging de l'expÃ©rience
    
    log_experiment(
        agent_name="Auditor",
        model_used=agentTest.model.model,
        action=ActionType.ANALYSIS,
        details={
            "input_prompt": AUDITOR_SYSTEM_PROMPT + "\n" + user_prompt,
            "output_response": audit_content
        },
        status=status
    )


    
    return {
        "refactor_plan": [audit_content]
    }

    